{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiment1.ipynb",
      "provenance": [],
      "mount_file_id": "1-seP6vvgRYfoI4TDm27IL_CkeC04u3kF",
      "authorship_tag": "ABX9TyMnoNOvBeJU0Xztfuu56sJG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranitha2144/SignLanguagetoText/blob/main/Experiment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-fcs8dzWw-j"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense , Dropout\n",
        "from tensorflow.keras import models\n",
        "import numpy as np\n",
        "\n",
        "sz=128"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhcCNdooW6yG",
        "outputId": "9c1a9f0a-3250-4b88-f79b-43172ff8e1be"
      },
      "source": [
        "# load json and create model\n",
        "json_file = open('/content/drive/MyDrive/Major project- IV-II/model-bw.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = models.model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"/content/drive/MyDrive/Major project- IV-II/model-bw.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "loss, acc= loaded_model.evaluate(test_set, verbose=2)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n",
            "427/427 - 25s - loss: 4.8443e-05 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0ciAGETrBS1"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvff9mfUrFQV"
      },
      "source": [
        "img_path = \"/content/drive/MyDrive/Major project- IV-II/test/W/117.jpg\"\n",
        "img = image.load_img(img_path, target_size=(128, 128,1),color_mode='grayscale')"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0RhLbMjrhix"
      },
      "source": [
        "img_array = image.img_to_array(img)\n",
        "img_batch = np.expand_dims(img_array, axis=0)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "1RH43YFTrlRD",
        "outputId": "2948fbe5-6e16-4f8d-a14e-b652896bc44b"
      },
      "source": [
        ""
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-2844c890ebd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_preprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/applications/resnet.py\u001b[0m in \u001b[0;36mpreprocess_input\u001b[0;34m(x, data_format)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m   return imagenet_utils.preprocess_input(\n\u001b[0;32m--> 521\u001b[0;31m       x, data_format=data_format, mode='caffe')\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36mpreprocess_input\u001b[0;34m(x, data_format, mode)\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     return _preprocess_numpy_input(\n\u001b[0;32m--> 116\u001b[0;31m         x, data_format=data_format, mode=mode)\n\u001b[0m\u001b[1;32m    117\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     return _preprocess_symbolic_input(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36m_preprocess_numpy_input\u001b[0;34m(x, data_format, mode)\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 3 with size 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlm5ZZiDrpFa",
        "outputId": "e284821c-630c-4e49-b523-9e03f3bdb93f"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "prediction = loaded_model.predict(img_batch)\n",
        "np.argmax(prediction)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_3_QLm0vPz4",
        "outputId": "be17c6b6-635a-4461-b078-8a6d1a3e11a4"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "labels=['0','A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
        "data_path='/content/drive/MyDrive/Major project- IV-II/test'\n",
        "data_dir_list=os.listdir(data_path)\n",
        "for dataset in data_dir_list:\n",
        "  print(dataset)\n",
        "  img_list=os.listdir(data_path+'/'+dataset)\n",
        "  correctCount=0\n",
        "  wrongCount=0\n",
        "  for img in img_list:\n",
        "    img_path=data_path+'/'+dataset+'/'+img\n",
        "    img = image.load_img(img_path, target_size=(128, 128,1),color_mode='grayscale')\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_batch = np.expand_dims(img_array, axis=0)\n",
        "    output = loaded_model.predict(img_batch)\n",
        "    ans=np.argmax(output)\n",
        "    if( labels[ans] == dataset):\n",
        "      correctCount+=1\n",
        "    else:\n",
        "      wrongCount+=1\n",
        "  print(dataset,\"correct Count {} WrongCount {}\".format(correctCount,wrongCount))"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E\n",
            "E correct Count 155 WrongCount 1\n",
            "T\n",
            "T correct Count 152 WrongCount 3\n",
            "I\n",
            "I correct Count 77 WrongCount 80\n",
            "O\n",
            "O correct Count 167 WrongCount 0\n",
            "M\n",
            "M correct Count 160 WrongCount 5\n",
            "Z\n",
            "Z correct Count 156 WrongCount 0\n",
            "P\n",
            "P correct Count 155 WrongCount 0\n",
            "S\n",
            "S correct Count 125 WrongCount 29\n",
            "A\n",
            "A correct Count 137 WrongCount 19\n",
            "V\n",
            "V correct Count 162 WrongCount 1\n",
            "G\n",
            "G correct Count 151 WrongCount 2\n",
            "H\n",
            "H correct Count 138 WrongCount 27\n",
            "J\n",
            "J correct Count 166 WrongCount 0\n",
            "Q\n",
            "Q correct Count 136 WrongCount 18\n",
            "B\n",
            "B correct Count 145 WrongCount 12\n",
            "W\n",
            "W correct Count 150 WrongCount 6\n",
            "F\n",
            "F correct Count 132 WrongCount 33\n",
            "L\n",
            "L correct Count 155 WrongCount 0\n",
            "X\n",
            "X correct Count 148 WrongCount 5\n",
            "Y\n",
            "Y correct Count 158 WrongCount 0\n",
            "C\n",
            "C correct Count 156 WrongCount 0\n",
            "R\n",
            "R correct Count 157 WrongCount 0\n",
            "0\n",
            "0 correct Count 138 WrongCount 16\n",
            "K\n",
            "K correct Count 164 WrongCount 0\n",
            "D\n",
            "D correct Count 142 WrongCount 13\n",
            "U\n",
            "U correct Count 103 WrongCount 50\n",
            "N\n",
            "N correct Count 159 WrongCount 4\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}